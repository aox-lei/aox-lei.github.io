<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Docker's Blog</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2017-09-21T00:00:00+08:00</updated><entry><title>ProxyTool代理池功能, 免费获取ip代理</title><link href="/python/1.html" rel="alternate"></link><published>2017-09-21T00:00:00+08:00</published><updated>2017-09-21T00:00:00+08:00</updated><author><name>Docker</name></author><id>tag:None,2017-09-21:/python/1.html</id><summary type="html">&lt;p&gt;这是第一篇php的文章&lt;/p&gt;
&lt;p&gt;在制作爬虫或者抓取别的网站的时候, 因为频率等稳定经常被封, 所以需要加代理ip, 但是因为各大网站的免费代理失效速度很快, 而且使用的时候抓取不方便, 所以开发了一个代理ip池, 免费获取代理ip,并且自动验证, 通过web接口, 直接可以获取到使用的代理ip。&lt;/p&gt;
&lt;p&gt;项目地址:https://github.com/mm333444/ProxyTool/&lt;/p&gt;
&lt;h1&gt;ProxyTool&lt;/h1&gt;
&lt;p&gt;python3搭建的代理池功能, 免费获取代理ip 每10分钟自动抓取ip66、ip181、xici代理的脚本, 保存到mongo中, 并且提供web接口, 方便搭建调用
环境: python3.6.2&lt;/p&gt;
&lt;h2&gt;一、安装方法&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install -r requirements.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;二、使用方法&lt;/h2&gt;
&lt;p&gt;-env 指定环境, 会读取app.config下指定的配置文件&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python run.py -env online
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;三、 基本逻辑 …&lt;/h2&gt;</summary><content type="html">&lt;p&gt;这是第一篇php的文章&lt;/p&gt;
&lt;p&gt;在制作爬虫或者抓取别的网站的时候, 因为频率等稳定经常被封, 所以需要加代理ip, 但是因为各大网站的免费代理失效速度很快, 而且使用的时候抓取不方便, 所以开发了一个代理ip池, 免费获取代理ip,并且自动验证, 通过web接口, 直接可以获取到使用的代理ip。&lt;/p&gt;
&lt;p&gt;项目地址:https://github.com/mm333444/ProxyTool/&lt;/p&gt;
&lt;h1&gt;ProxyTool&lt;/h1&gt;
&lt;p&gt;python3搭建的代理池功能, 免费获取代理ip 每10分钟自动抓取ip66、ip181、xici代理的脚本, 保存到mongo中, 并且提供web接口, 方便搭建调用
环境: python3.6.2&lt;/p&gt;
&lt;h2&gt;一、安装方法&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install -r requirements.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;二、使用方法&lt;/h2&gt;
&lt;p&gt;-env 指定环境, 会读取app.config下指定的配置文件&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python run.py -env online
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;三、 基本逻辑&lt;/h2&gt;
&lt;p&gt;整个项目分为三部分 抓取、验证和web接口&lt;/p&gt;
&lt;h3&gt;一、抓取&lt;/h3&gt;
&lt;p&gt;在app/crawl目录下, 每个网站对应的一个文件, 可以自己扩展, 基本代码可以查看app/crawl/下的文件&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;app.util.function&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;now&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;app.crawl.base&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;base&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;xici&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 最大抓取页数&lt;/span&gt;
    &lt;span class="n"&gt;max_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;anonymous_proxy_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.xicidaili.com/nn/&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;common_proxy_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.xicidaili.com/nt/&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;https_proxy_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.xicidaili.com/wn/&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;http_proxy_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.xicidaili.com/wt/&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="err"&gt;要抓取的&lt;/span&gt;&lt;span class="n"&gt;url可以传入&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;抓取列表页调用&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_crawl_page&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;抓取单页调用&lt;/span&gt;&lt;span class="n"&gt;_crawl_single&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_parse_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="err"&gt;抓取后&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;将页面中的内容解析出来&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;二、验证&lt;/h3&gt;
&lt;p&gt;验证是在app/validate目录下, 目前只实现了请求百度验证的方式&lt;/p&gt;
&lt;h3&gt;三、web接口&lt;/h3&gt;
&lt;p&gt;web接口目前只实现的get接口, 默认绑定端口为8899
访问地址:http://网址/get/&amp;lt;要获取的ip数量&amp;gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[
    {
        ip: &amp;quot;114.82.159.57&amp;quot;,
        type: &amp;quot;HTTPS&amp;quot;, # type有三个值, https,http和all, all代表支持http和https两种
        port: &amp;quot;8118&amp;quot;,
        speed: 1 # 请求速度, 越小说明越快
    },
    {
        ip: &amp;quot;223.150.73.245&amp;quot;,
        type: &amp;quot;HTTP&amp;quot;,
        port: &amp;quot;80&amp;quot;,
        speed: 1
    }
]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果在使用中有什么问题可以发issue, 如果真的对您有什么作用的话, 请给个star&lt;/p&gt;</content></entry></feed>